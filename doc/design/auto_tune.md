



# Sophgo_mlir Auto_tune

## 一、总体介绍

  Sophgo mlir中量化auto_tune功能参考了晶视工具链的成熟实现，但相比而言，有如下几方面的改进：

1.  快速：修改某个op的输入th后，不再需要对整个网络进行量化，推理时，也不需要从输入层一直推理到目标op，只需对目标op这一层进行推理即可；

2.  内存占用少：若需要用200张图进行auto tune，则老的方案需要在内存中分配所有这200张图的各层推理激活，这占用内存非常大，基本无法满足，而新方案是按需进行激活tensor的计算生成，若这些激活不再被需要，就会立即被释放掉，从而目前可支持用远大于先前方案的图片数量来进行auto tune；

3. 更细粒度的调节：因为执行效率大幅提升，可对threahold到abs_max这区间的候选值进行更细粒度的搜索，有助于达成最佳结果；

4. 更通用：不依赖具体类型层的量化算法实现，实现一个通用、适应性广的方法；

## 二、方案介绍

1. 加载2个pymlir推理对象：model_ref用于生成参考的fp32激活，model_quant用于量化op推理，首先针对model_quant对象调用fake_quant_weight接口对加载的top.Weight进行统一的per-tensor max量化，统一针对权重引入量化误差，这里是一种通用的方法，不考虑各具体类型op的差异，也不考虑th对权重量化的影响；

2.  遍历op列表，对除top.Input外的op进行处理：若op的所有输入th都已调节过，则任选1个来调节th（详见下面3.1节解释），若有某个输入th未调节过，就对它进行调节；

3.  针对某个op1的输入op2输出激活的th调节方法为：首先，生成所有图片的op1参考fp32输出、生成所有图片的op2的输出激活值（也即op1的输入激活），这里对op2进行推理时，使用的op2的输入th已经调整好，且其输入激活也是前面op推理输出结果，该激活已累积了前面各op的量化误差，这些生成好的数据被保存好备用； 然后，在一个循环中，生成更新后的门限，用这个新门限对op1的输入激活进行量化反量化引入量化误差，然后使用前面已引入量化误差的权重进行推理（调用model_quant.invoke_at(op1)），生成int8的op1输出激活，然后获取前面生成的fp32的op1参考输出激活，进行欧式距离的计算，将所有tune图片的欧式距离求平均，若得到的平均距离小于前面记录的最小距离，则当前更新门限为更优门限，保存；最终，在完成初始threahold到abs_max间均匀分布的所有预定义个数的候选th值后，将最佳的th值保存到calibration_table表中；


